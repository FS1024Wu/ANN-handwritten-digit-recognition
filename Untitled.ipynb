{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numP\n",
    "from decimal import Decimal\n",
    "from PIL import Image\n",
    "import glob\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "from numpy.linalg import inv\n",
    "import gc\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column headings: Index(['Label',       1,       2,       3,       4,       5,       6,       7,\n",
      "             8,       9,\n",
      "       ...\n",
      "           775,     776,     777,     778,     779,     780,     781,     782,\n",
      "           783,     784],\n",
      "      dtype='object', length=785)\n"
     ]
    }
   ],
   "source": [
    "train_label=[]\n",
    "train_iamge=[]\n",
    "softmax_actual_y = [0]*10\n",
    "bias1 = [random.uniform(0, 1)]*10\n",
    "bias2 = [random.uniform(0, 1)]*10\n",
    "weight_nodes    = numP.random.rand(10,784)\n",
    "weight_hidden_nodes    = numP.random.rand(10,10)\n",
    "tData = pd.read_excel(r\"C:\\Users\\sheng\\Desktop\\BigData\\icollege\\mnist_test.xlsx\", sheet_name='mnist_test')\n",
    "row_N = tData.shape[0]\n",
    "col_N = tData.shape[1]\n",
    "print(\"Column headings:\",tData.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (10):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    temp=tData.iloc[i,0]\n",
    "    y.append(temp)\n",
    "    for j in range (784):\n",
    "        temp=tData.iloc[i,j+1]\n",
    "        x.append(temp)\n",
    "    train_label.append(y)\n",
    "    train_iamge.append(x)\n",
    "    \n",
    "train_label = numP.matrix(train_label,dtype='float64')\n",
    "train_iamge = numP.matrix(train_iamge,dtype='float64') / 255\n",
    "##print(train_label.shape,train_label[0][0],train_iamge.shape) //(10, 1) [[7.]] (10, 784)\n",
    "##print(train_iamge[0][0,0:27])\n",
    "##for i in range(27):\n",
    "##    if(i!=0):\n",
    "##        print(train_iamge[0][0,(28*i):(28*(i+1)-1)])\n",
    "##\n",
    "weight_nodes    = numP.matrix(weight_nodes,dtype='float64')\n",
    "weight_hidden_nodes     = numP.matrix(weight_hidden_nodes,dtype='float64')\n",
    "bia_hidden      = numP.matrix(bias1,dtype='float64')\n",
    "bia_softmax_op  = numP.matrix(bias2,dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer y =  [[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]] (1, 10) 1.0\n",
      "predict output layer y =  [[0.99513505 0.98973278 0.98909644 0.99928593 0.9614226  0.99277385\n",
      "  0.99500641 0.99655675 0.99486864 0.98470898]]\n",
      "actural output layer y =  7.0  @  [[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y_hidden_node = []\n",
    "y_output_node = []\n",
    "\n",
    "for j in range(1):\n",
    "    temp=[]\n",
    "    for i in range(10):                                                  #\n",
    "        temp.append(1/(1+math.exp(-1*(train_iamge[j] * (weight_nodes[i].T)+ bia_hidden[0][0,i] ))))\n",
    "    y_hidden_node.append(temp)\n",
    "y_hidden_node = numP.matrix(y_hidden_node,dtype='float64')\n",
    "print(\"hidden layer y = \",y_hidden_node,y_hidden_node.shape,y_hidden_node[0][0,9])\n",
    "\n",
    "for i in range(10):\n",
    "    y_output_node.append(1/(1+math.exp(-1*(y_hidden_node[0] * (weight_hidden_nodes[i].T) + bia_softmax_op[0][0,i]))))\n",
    "    if(train_label[0][0,0]==i):\n",
    "        softmax_actual_y[i-1] = 1\n",
    "    else:\n",
    "        softmax_actual_y[i-1] = 0        \n",
    "y_output_node = numP.matrix(y_output_node,dtype='float64')\n",
    "softmax_actual_y = numP.matrix(softmax_actual_y,dtype='float64')\n",
    "print(\"predict output layer y = \",y_output_node)\n",
    "print(\"actural output layer y = \",train_label[0][0,0],\" @ \",softmax_actual_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squa error =  4.404623952550629\n"
     ]
    }
   ],
   "source": [
    "total_error = 0\n",
    "for i in range (10):\n",
    "    total_error += 0.5 * (math.pow((softmax_actual_y[0][0,i]-y_output_node[0][0,i]),2))\n",
    "print(\"Mean squa error = \",total_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaabbb\n"
     ]
    }
   ],
   "source": [
    "print(\"aaaabbb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_node_weight= \n",
      " [[0.54349234 0.6643544  0.51418041 0.05374134 0.5985904  0.95713256\n",
      "  0.35978684 0.96762938 0.14700823 0.31161858]\n",
      " [0.39248769 0.26163028 0.3588312  0.78792994 0.65873804 0.02751073\n",
      "  0.50018605 0.11783185 0.86212601 0.39791875]\n",
      " [0.44602813 0.28613775 0.93550063 0.07195588 0.43307252 0.73097161\n",
      "  0.33945018 0.62930616 0.3789291  0.05306295]\n",
      " [0.82627002 0.90661212 0.92816095 0.6722891  0.16967226 0.73204141\n",
      "  0.76361033 0.28028048 0.84862805 0.91296501]\n",
      " [0.45414927 0.21735824 0.31922374 0.22893046 0.18140022 0.13858064\n",
      "  0.79614174 0.17982308 0.4088524  0.08800008]\n",
      " [0.81159556 0.21738011 0.17271827 0.80261894 0.97701738 0.55305814\n",
      "  0.07850345 0.83355791 0.14495753 0.12810196]\n",
      " [0.71077375 0.4788292  0.41972316 0.58158346 0.58964189 0.03843335\n",
      "  0.67819834 0.1732515  0.5891322  0.83173946]\n",
      " [0.94120522 0.66116872 0.37257837 0.96257337 0.38084396 0.70689584\n",
      "  0.92875222 0.24063567 0.13872542 0.13122246]\n",
      " [0.93440778 0.47774169 0.8025489  0.11186746 0.77637753 0.2837445\n",
      "  0.65204068 0.07365528 0.56967418 0.38189454]\n",
      " [0.08637512 0.6273636  0.39798933 0.56684755 0.30346791 0.53793394\n",
      "  0.22560008 0.40113291 0.12278228 0.69230008]]\n",
      "Update_hidden_node_weight= \n",
      " [[0.54180614 0.66266819 0.51249421 0.05205513 0.59690419 0.95544636\n",
      "  0.35810064 0.96594317 0.14532202 0.30993238]\n",
      " [0.38896758 0.25811016 0.35531109 0.78440982 0.65521793 0.02399062\n",
      "  0.49666593 0.11431173 0.8586059  0.39439863]\n",
      " [0.44229465 0.28240427 0.93176716 0.0682224  0.42933905 0.72723813\n",
      "  0.33571671 0.62557268 0.37519563 0.04932947]\n",
      " [0.82602046 0.90636256 0.92791138 0.67203953 0.16942269 0.73179185\n",
      "  0.76336076 0.28003092 0.84837849 0.91271544]\n",
      " [0.44166883 0.20487781 0.3067433  0.21645003 0.16891979 0.12610021\n",
      "  0.78366131 0.16734265 0.39637197 0.07551964]\n",
      " [0.80910283 0.21488738 0.17022554 0.80012621 0.97452465 0.55056541\n",
      "  0.07601072 0.83106517 0.1424648  0.12560923]\n",
      " [0.71078244 0.47883788 0.41973185 0.58159214 0.58965058 0.03844203\n",
      "  0.67820702 0.17326018 0.58914089 0.83174814]\n",
      " [0.94000836 0.65997186 0.37138152 0.96137651 0.37964711 0.70569899\n",
      "  0.92755536 0.23943881 0.13752856 0.1300256 ]\n",
      " [0.93263019 0.4759641  0.80077131 0.11008986 0.77459994 0.28196691\n",
      "  0.65026309 0.07187769 0.56789659 0.38011695]\n",
      " [0.08118568 0.62217416 0.39279989 0.56165811 0.29827848 0.5327445\n",
      "  0.22041065 0.39594347 0.11759284 0.68711064]]\n"
     ]
    }
   ],
   "source": [
    "## backpropogation and min error rate.\n",
    "##hidden layer nood weight update\n",
    "update_weight_hidden_layer = []\n",
    "learning_rate = 0.35\n",
    "for i in range(10):\n",
    "    new_weight=[]\n",
    "    for j in range(10):\n",
    "        new_weight.append(weight_hidden_nodes[i].T[j][0,0]-learning_rate*(y_hidden_node[0][0,j]*y_output_node[0][0,i]*(1-y_output_node[0][0,i])*(y_output_node[0][0,i]-softmax_actual_y[0][0,i])))\n",
    "    update_weight_hidden_layer.append(new_weight)\n",
    "update_weight_hidden_layer = numP.matrix(update_weight_hidden_layer,dtype='float64')\n",
    "print(\"hidden_node_weight= \\n\",weight_hidden_nodes)\n",
    "print(\"Update_hidden_node_weight= \\n\",update_weight_hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-4cad9e03226f>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-28-4cad9e03226f>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    sum_op_h1 += (y_output_node[0][0,i]-softmax_actual_y[0][0,i])*y_hidden_node[0][0,i]*(1-y_hidden_node[0][0,i])*\u001b[0m\n\u001b[1;37m                                                                                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "update_weight_input_layer = []\n",
    "sum_op_h1 = 0\n",
    "learning_rate = 0.5\n",
    "for i in range(10):\n",
    "    sum_op_h1 += (y_output_node[0][0,i]-softmax_actual_y[0][0,i])*y_hidden_node[0][0,i]*(1-y_hidden_node[0][0,i])*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
